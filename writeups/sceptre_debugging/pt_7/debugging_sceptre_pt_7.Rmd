---
title: "Debugging `sceptre` part 7"
author: "Tim"
date: "2022-11-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this writeup I examine the following:

1.  How does sample size vary across datasets?

2.  How does the "exact" version of SCEPTRE (i.e., the version of SCEPTRE that returns an "exact" p-value based on B = 300,000 resamples) perform on the Frangieh IFN-gamma and Papalexi gene data?

A question that I seek to answer is whether SCEPTRE exhibits CAMP, or "Confounder Adjustment via Marginal Permutations" (previously known as "implicit confounder adjustment").

# Sample size

```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(katlabutils)
library(tidyverse)
result_dir <- paste0(.get_config_path("LOCAL_SCEPTRE2_DATA_DIR"), "results/")

replace_slash_w_underscore <- function(df) {
  df |> dplyr::mutate(dataset = gsub(pattern = "/",
                                replacement = "_",
                                fixed = TRUE,
                                x = dataset))
}

funct_script <- paste0(.get_config_path("LOCAL_CODE_DIR"), "sceptre2-manuscript/writeups/undercover_results_eda/analyze_undercover_results_plot_functs.R")
source(funct_script)

sample_size_df <- readRDS(paste0(result_dir,
                                    "dataset_sample_sizes/n_nonzero_cells_per_grna.rds")) |>
  dplyr::mutate(dataset = dataset_concat,
                dataset_concat = NULL, paper = NULL, modality = NULL) |>
  dplyr::rename(grna_group = target, response_id = feature_id) |>
  replace_slash_w_underscore() |>
  combine_schraivogel_enhancer_screens() |>
  filter(dataset %in% c("frangieh_co_culture_gene",
                        "frangieh_control_gene",
                        "frangieh_ifn_gamma_gene",
                        "papalexi_eccite_screen_gene",
                        "schraivogel_enhancer_screen",
                        "schraivogel_ground_truth_perturbseq_gene",
                        "schraivogel_ground_truth_tapseq_gene"))
paper <- factor(x = sample_size_df$dataset,
       levels = c("frangieh_co_culture_gene",
                  "frangieh_control_gene",
                  "frangieh_ifn_gamma_gene",
                  "papalexi_eccite_screen_gene",
                  "schraivogel_ground_truth_perturbseq_gene",
                  "schraivogel_enhancer_screen",
                  "schraivogel_ground_truth_tapseq_gene"),
       labels = c(rep("Frangieh", 3), "Papalexi", rep("Schraivogel", 3)))
sample_size_df$paper <- paper
sample_size_df$dataset_rename <- stringr::str_to_title(gsub(pattern = "_", replacement = " ", x = sample_size_df$dataset)) |> factor()

sample_size_df_nt <- sample_size_df |>
  filter(grna_group == "non-targeting")
sample_size_df_t <- sample_size_df |>
  filter(grna_group != "non-targeting")

ntc_effective_samp_size <- sample_size_df_nt |>
  group_by(response_id, dataset) |>
  summarize(effective_samp_size = sum(n_nonzero_cells))

sample_size_df_nt <- left_join(x = sample_size_df_nt,
                            y = ntc_effective_samp_size,
                            by = c("response_id", "dataset")) |>
  mutate(n_nonzero_treatment = n_nonzero_cells,
         n_nonzero_control = effective_samp_size - n_nonzero_cells) |>
  rename("undercover_grna" = "grna_id")
```

Sample size has emerged as an important quantity in low MOI (and even in high MOI). Here, I study issues related to sample size in a more precise and in-depth way than I have previously.

### Definitions of relevant quantities

I begin by defining several quantities -- `n_nonzero_treatment`, `n_nonzero_control`, and `effective_sample_size` -- on the negative control data. Let a dataset be given. Let $d$ be the number of NTCs, let $p$ be the number of genes, and let $n$ be the number of cells in the dataset. Let $X \in \mathbb{R}^{n \times p}$ be the cell-by-gene expression matrix. Next, for $k \in \{1, â€¦, d\},$ let $n_k$ be the number of cells containing NTC $k$ (where the NTCs are arbitrarily indexed). Also, let $X^{1} \in \mathbb{R}^{n_1 \times p}$ be the submatrix of $X$ consisting of the cells that received NT 1 (and similarly for $X^2, \dots, X^d$). For a given NTC $k$ and gene $j$, let \$\$\\texttt{n_nonzero_treatment}\_{kj}\$\$ be the number of cells containing NTC $k$ in which gene $j$ has nonzero expression, i.e.

$$ \texttt{n_nonzero_treatment}_{jk} = \sum_{i=1}^{n_k} \mathbb{I}(X^k_{i,j} \geq 1).$$

Next, let $\texttt{n_nonzero_control}_{kj}$ be the number of NT-containg cells *excluding* NTC $k$ (i.e., the cells containing NTCs in the set $[d] \setminus \{k\}$) with nonzero expression, i.e.,

$$
\texttt{n_nonzero_control}_{jk} = \sum_{k' \neq k} \texttt{n_nonzero_treatment}_{k'j}
$$

Finally, let `effective_sample_size` be the sum of `n_nonzero_treatment` and `n_nonzero_control`. On the negative control data, `effective_sample_size` is a function of the gene only:

$$
 \texttt{effective_sample_size}_j = \sum_{k = 1}^d \texttt{n_nonzero_treatment}_{jk}
$$

I study how `effective_sample_size`, `n_nonzero_treatment`, and `n_nonzero_control` relate to one another.

### Empirical relationship between `effective_sample_size`, `n_nonzero_treatment`, and `n_nonzero_control`

First, I plot `n_nonzero_treatment` against `effective_sample_size`, faceting by dataset. In other words, I plot

$$
\{ (\texttt{n_nonzero_treatment}_{jk}, \texttt{effective_sample_size}_{j})\}_{j,k} 
$$

for each dataset.

```{r, echo = FALSE, fig.align = "center", fig.height = 8, fig.width = 8, message=FALSE, warning=FALSE}
sample_size_df_nt |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(effective_samp_size, n_nonzero_treatment)) +
  geom_point(alpha = 0.7, cex = 0.7) +
  facet_wrap(dataset_rename ~ ., scales = "free", labeller = label_wrap_gen(35)) +
  theme_bw() +
  xlab("Effective sample size") +
  ylab("N nonzero treatment")
```

Clearly, `n_nonzero_treatment` and `effective_sample_size` are correlated. This makes sense: for a given gene, if expression is high in cells with a given NTC, then expression likely is high in cells with the remaining NTCs. (Put differently, expression levels are correlated across NTCs: highly expressed genes tend to be highly expressed across NTCs, and similarly for lowly expressed genes.)

Next, I plot `n_nonzero_control` against `effective_sample_size`, i.e.

\$\$\\{(\\texttt{n_nonzero_control}\_{jk}, \\texttt{effective_sample_size}\_{j})\\}\_{j,k}\$\$

```{r, echo = FALSE, fig.align = "center", fig.height = 8, fig.width = 8, message=FALSE, warning=FALSE}
sample_size_df_nt |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(effective_samp_size, n_nonzero_control)) +
  geom_point(alpha = 0.7, cex = 0.7) +
  facet_wrap(dataset ~ ., scales = "free", labeller = label_wrap_gen(35)) +
  theme_bw() +
  xlab("Effective sample size") +
  ylab("N nonzero control")
```

Clearly, `n_nonzero_control` and `effective_sample_size` are basically the same variable. Again, this makes sense: for a given gRNA, `n_nonzero_control` is equal to `effective_sample_size` minus the number of cells with nonzero expression containing that gRNA. Finally, I plot `n_nonzero_treatment` against `n_nonzero_control`.

```{r, echo = FALSE, fig.align = "center", fig.height = 8, fig.width = 8, message=FALSE, warning=FALSE}
sample_size_df_nt |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(n_nonzero_treatment, n_nonzero_control)) +
  geom_point(alpha = 0.7, cex = 0.7) +
  facet_wrap(dataset ~ ., scales = "free", labeller = label_wrap_gen(35)) +
  theme_bw() +
  xlab("Effective sample size") +
  ylab("N nonzero control")
```

Again, these variables are correlated (but certainly not perfectly) for the same reason that `n_nonzero_treatment` and `effective_sample_size` are correlated.

I conclude on the basis of this analysis that, while `effective_sample_size` is a useful single-number summary of sample size, it is meaningful to look at both at `n_nonzero_treatment` and `n_nonzero_control` when examining sample size-related issues.

### Comparison across datasets

Here, I make some comparisons related to sample size across datasets. First, I make a barplot of the number of NTCs per dataset.

```{r, echo = FALSE, fig.align = "center", fig.height = 7, fig.width = 5, message=FALSE, warning=FALSE}
n_ntc_df <- sample_size_df_nt |>
  select(undercover_grna, dataset_rename, paper) |>
  distinct() |>
  group_by(dataset_rename) |>
  summarize(count = n(), paper = paper[1])

n_ntc_df |>
  ggplot(mapping = aes(x = dataset_rename, y = count, fill = paper)) +
  geom_bar(stat = "identity", col = "black") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylab("N NTCs") + xlab("Dataset")
```

The Frangieh data contain the greatest number of NTCs, followed by the Schraivogel data and then the Papalexi data. Next, I plot the average number of nonzero cells per NTC (i.e., `n_nonzero_treatment`) across datasets.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
sample_size_df_nt |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(y = n_nonzero_treatment + 1, x = dataset_rename, fill = paper)) +
  geom_violin() +
  geom_boxplot() +
  scale_y_log10() +
  ylab("N nonzero treatment") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

I print the median `n_nonzero_treatment` value for each dataset below.

```{r}
sample_size_df_nt |>
  group_by(dataset) |>
  summarize(m = median(n_nonzero_treatment))
```

The Frangieh data have the smallest number nonzero cells per NTC (median under 10). The Papalexi data are indermediate (median about 30), and the Schraivogel data have the greatest number of cells per NTC (median 37 on perturb-seq data; even greater median on other datasets). Finally, I plot the `effective_sample_size` per dataset.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
sample_size_df_nt |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(y = effective_samp_size + 1, x = dataset_rename, fill = paper)) +
  geom_violin() +
  geom_boxplot() +
  scale_y_log10() +
  ylab("Effective sample size") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

I print the per-dataset median effective sample size below.

```{r}
sample_size_df_nt |>
  group_by(dataset) |>
  summarize(m = median(effective_samp_size))
```

We see that the effective sample sizes are in a similar range on the Frangieh and Papalexi datasets (while the effective sample sizes on the Schraivogel datasets are larger). The Frangieh data have fewer nonzero cells per NTC but many more NTCs than the Papalexi data, causing the effective sample size to be roughly equal across the Frangieh and Papalexi data.

Now, I examine the number of nonzero cells per targeting gRNA (grouped and ungrouped) across datasets.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
sample_size_df_t |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(x = dataset_rename,
                       y = n_nonzero_cells + 1,
                       fill = paper)) +
  geom_violin() +
  geom_boxplot() +
  scale_y_log10() +
  ylab("N nonzero cells per targeting gRNA (ungrouped)") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
sample_size_df_t |>
  group_by(dataset) |>
  summarize(median_nonzero = median(n_nonzero_cells))
```

Next, I plot the number of nonzero cells per gRNA group:

```{r, echo = FALSE}
grouped_ss_df <- sample_size_df_t |>
  group_by(dataset, grna_group, response_id) |>
  summarize(s = sum(n_nonzero_cells))

grouped_ss_df$dataset_rename <- stringr::str_to_title(gsub(pattern = "_",
                                                            replacement = " ",
                                                            x = grouped_ss_df$dataset))
paper <- factor(x = grouped_ss_df$dataset,
       levels = c("frangieh_co_culture_gene",
                  "frangieh_control_gene",
                  "frangieh_ifn_gamma_gene",
                  "papalexi_eccite_screen_gene",
                  "schraivogel_ground_truth_perturbseq_gene",
                  "schraivogel_enhancer_screen",
                  "schraivogel_ground_truth_tapseq_gene"),
       labels = c(rep("Frangieh", 3), "Papalexi", rep("Schraivogel", 3)))
grouped_ss_df$paper <- paper

grouped_ss_df |>
  group_by(dataset) |>
  sample_n(10000, replace = TRUE) |>
  ggplot(mapping = aes(x = dataset_rename,
                       y = s + 1,
                       fill = paper)) +
  geom_violin() +
  geom_boxplot() +
  scale_y_log10() +
  ylab("N nonzero cells per targeting gRNA (ungrouped)") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

# Number of hypotheses

First, I plot the number of genes per dataset (after applying mild QC of filtering out genes expressed in fewer than 0.005 of cells).

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
n_gene_df <- sample_size_df_nt |>
  select(response_id, dataset_rename, paper) |>
  distinct() |>
  group_by(dataset_rename) |>
  summarize(count = n(), paper = paper[1])

n_pair_df <- n_gene_df |>
  mutate(n_pairs = count * n_ntc_df$count) |>
  select(-count)

n_gene_df |>
  ggplot(mapping = aes(x = dataset_rename, y = count, fill = paper)) +
  geom_bar(stat = "identity", col = "black") +
  theme_bw() +
  xlab("Dataset") +
  ylab("N genes") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

All datasets have roughly the same number of genes (about 15,000) except for the TAP-seq and enhancer screen datasets (which of course have fewer genes). Next, I plot the number of pairs across datasets.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
n_pair_df |>
  ggplot(mapping = aes(x = dataset_rename, y = n_pairs, fill = paper)) +
  geom_bar(stat = "identity", col = "black") +
  theme_bw() +
  xlab("Dataset") +
  ylab("N genes") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

The Frangieh data of course contain more pairs because they contain more NT gRNAs.

# Exact SCEPTRE

I applied the exact version of SCEPTRE (with covariates and using B = 300,000 permutations) to the Papalexi data and Frangieh data.

```{r, echo = FALSE}
library(katlabutils) 
library(tidyverse) 
result_dir <- paste0(.get_config_path("LOCAL_SCEPTRE2_DATA_DIR"), "results/")

replace_slash_w_underscore <- function(df) {
  df |> dplyr::mutate(dataset = gsub(pattern = "/",
                                replacement = "_",
                                fixed = TRUE,
                                x = dataset))
}

funct_script <- paste0(.get_config_path("LOCAL_CODE_DIR"), "sceptre2-manuscript/writeups/undercover_results_eda/analyze_undercover_results_plot_functs.R") 
source(funct_script) 

# 1. sceptre big b
sceptre_big_B <- readRDS(paste0(result_dir, "undercover_grna_analysis/sceptre_debug_bigB_frang_papa.rds")) |>
  mutate(method = "sceptre (exact cov)") |>
  replace_slash_w_underscore()

# 1.5 sceptre big b without covariates
sceptre_big_B_no_cov <- readRDS(paste0(result_dir, "undercover_grna_analysis/sceptre_debug_bigB_frang_papa_nocov.rds")) |>
  mutate(method = "sceptre (exact no cov)") |>
  replace_slash_w_underscore()

# 2. sceptre (with covariates)
sceptre_res_cov <- readRDS(paste0(result_dir,
                                  "undercover_grna_analysis/undercover_result_grp_size_1_sceptre.rds")) |>
  select(-clock_time, -max_ram) |>
  mutate(method = "sceptre (sn cov)")

# 3. sceptre (without covariates)
sceptre_res_no_cov <- readRDS(paste0(result_dir,
                                  "undercover_grna_analysis/sceptre_debug_no_cov.rds")) |>
  mutate(method = "sceptre (sn no cov)")

# 4. NB regression, seurat de
nb_reg_res <- readRDS(paste0(result_dir, "undercover_grna_analysis/undercover_result_grp_size_1.rds")) |>
  dplyr::select(-clock_time, -max_ram) |>
  dplyr::filter(method %in% c("nb_regression", "seurat_de"))

res <- rbind(sceptre_big_B,
             sceptre_big_B_no_cov,
             nb_reg_res,
             sceptre_res_cov,
             sceptre_res_no_cov) |>
  replace_slash_w_underscore() |>
  update_dataset_names()

sample_size_df_nt_select <- sample_size_df_nt |> select(response_id,
                                                        undercover_grna,
                                                        dataset,
                                                        n_nonzero_treatment,
                                                        n_nonzero_control,
                                                        effective_samp_size)
rm(sample_size_df_nt, nb_reg_res)

# append sample size info to res
res <- left_join(res, sample_size_df_nt_select,
                 by = c("response_id", "dataset", "undercover_grna"))
```

First, I plot the SCEPTRE exact results on the Frangieh data, comparing to (i) the skew-normal version of SCEPTRE (with covariates), (ii) NB regression, and (iii) SCEPTRE (SN). I plot the results twice: once without QC (top) and once with mild QC (bottom). ("Mild QC" entails filtering for pairs with at least 10 treatment cells with nonzero expression and 10 control cells with nonzero expression. See the next writeup (Writeup 8) for a justification of these thresholds.

```{r, echo = FALSE, fig.align = "center", fig.height = 12, fig.width = 5, message=FALSE, warning=FALSE}
n_nonzero_treatment_thresh <- 10
n_nonzero_control_thresh <- 10

p_qc <- res |>
  filter(dataset == "frangieh_ifn_gamma_gene",
         method != "sceptre (exact no cov)",
         n_nonzero_treatment >= n_nonzero_treatment_thresh,
         n_nonzero_control >= n_nonzero_control_thresh) |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("QC")

p_no_qc <- res |>
  filter(dataset == "frangieh_ifn_gamma_gene",
         method != "sceptre (exact no cov)") |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) + 
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("No QC")

p <- cowplot::plot_grid(p_no_qc, p_qc, ncol = 1, labels = c("a", "b"))
p
```

SCEPTRE (exact) exhibits good calibration regardless of whether we apply QC. SCEPTRE (SN) and Seurat DE exhibit similar performance on the QC'ed and non-QC'ed data. Furthermore, these methods both perform better on the QC'ed data than on the non-QC'ed data, likely because the CLT-based approximation that these methods employ is better on the QC'ed data. Finally, NB regression does not seem to improve much (or at all) as we apply more stringent QC. This might be due to model misspecification for some fraction of hypotheses tested. The interaction between QC level and method performance is fairly striking (and perhaps expected, given the extent to which these methods rely on the CLT).

Next, I create the same set of plots for the Papalexi data. I plot SCEPTRE (exact), SCEPTRE (SN), Seurat DE, and NB regression. The top plot shows the results on the un-QC'ed data, and the bottom plot shows the results on the QC'ed data (where, again, QC entails filtering for pairs with \>7 treatment cells with nonzero expression and \>30 control cells with nonzero expression).

```{r, echo = FALSE, fig.align = "center", fig.height = 12, fig.width = 5, message=FALSE, warning=FALSE}
p_qc <- res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         method != "sceptre (exact no cov)",
         n_nonzero_treatment >= n_nonzero_treatment_thresh,
         n_nonzero_control >= n_nonzero_control_thresh) |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("QC")

p_no_qc <- res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         method != "sceptre (exact no cov)") |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("No QC")

p <- cowplot::plot_grid(p_no_qc, p_qc, ncol = 1, labels = c("a", "b"))
p
```

I compute the fraction of negative control pairs removed after applying QC. Note that the fraction of pairs filtered on the negative control data should be be much greater than that on the rest of the data, as the negative control data have one fewer NT in the control group and only a single gRNA in the undercover group. (In other words, the sample sizes are generally smaller on the negative control data than on the rest of the data.)

```{r}
 res |>
   filter(dataset %in% c("frangieh_co_culture_gene",
                         "papalexi_eccite_screen_gene")) |>
   group_by(dataset) |>
   summarize(frac_removed =  1 - mean(n_nonzero_treatment >= n_nonzero_treatment_thresh & n_nonzero_control >= n_nonzero_control_thresh)) 
```

Interestingly, SCEPTRE (exact) is miscalibrated on the un-QCed data but is excellently calibrated on the QC'ed data. I conjecture that SCEPTRE (exact) is miscalibrated on the un-QC'ed data for the following reason: some of the pairs are confounded, and the sample size is too small for CAMP to have kicked in. On the QC'ed data, meanwhile, CAMP has kicked in, enabling SCEPTRE to return a well-calibrated p-value for the confounded pairs. In fact, on the QC'ed data, SCEPTRE (exact) exhibits the best calibration of all the methods and is even better than NB regression. This possibly is because NB regression is less robust than SCEPTRE to GLM model misspecification.

Two questions arise: first, why is SCEPTRE (SN) better calibrated than SCEPTRE (exact) on the non-QC'ed data? And second, why is NB regression better calibrated than SCEPTRE on the non-QC'ed data? I attempt to address the first question here. Below, I plot the SCEPTRE (exact) p-values against the SCEPTRE (SN) p-values on a transformed scale.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
x <- res |>
  select(response_id,
         p_value,
         undercover_grna,
         dataset,
         method,
         n_nonzero_treatment,
         n_nonzero_control) |>
  filter(method %in% c("sceptre (exact cov)", "sceptre (sn cov)"),
         dataset == "papalexi_eccite_screen_gene") 
comparison_df <- left_join(x |>
                             filter(method == "sceptre (exact cov)") |>
                             rename("p_value_exact" = "p_value"),
                           x |>
                             filter(method == "sceptre (sn cov)") |>
                             rename("p_value_sn" = "p_value") |>
                             select(p_value_sn, response_id, undercover_grna),
                           by = c("response_id", "undercover_grna")) |>
  mutate(pass_qc = (n_nonzero_treatment >= n_nonzero_treatment_thresh) & (n_nonzero_control >= n_nonzero_control_thresh))

comparison_df |>
  ggplot(mapping = aes(x = p_value_exact, y = p_value_sn, col = pass_qc)) +
  geom_point(alpha = 0.7, cex = 0.7) +
  geom_abline(slope = 1, intercept = 0, col = "darkred") +
  theme_bw() +
  scale_x_continuous(trans = revlog_trans(10)) +
  scale_y_continuous(trans = revlog_trans(10)) +
  xlab("p-value (exact)") +
  ylab("p-value (SN)") +
  labs(col = "Retained after QC") +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  geom_vline(xintercept = 2e-2, col = "darkred") +
  geom_hline(yintercept = 3e-2, col = "darkred")
```

The SCEPTRE (SN) p-values are in broad agreement with the SCEPTRE (exact) p-values; however, the scatterplot has an obvious "appendage" below the diagonal. The pairs in this "appendage" have much smaller SCEPTRE (exact) p-values than SCEPTRE (SN) p-values. Nearly all the pairs in this appendage are filtered out by QC. Below, I create a similar plot to compare the SCEPTRE p-values to the negative binomial p-values.

```{r, echo = FALSE, fig.align = "center", fig.height = 5, fig.width = 5, message=FALSE, warning=FALSE}
x <- res |>
  select(response_id,
         p_value,
         undercover_grna,
         dataset,
         method,
         n_nonzero_treatment,
         n_nonzero_control) |>
  filter(method %in% c("sceptre (exact cov)", "nb_regression"),
         dataset == "papalexi_eccite_screen_gene") 
comparison_df <- left_join(x |>
                             filter(method == "sceptre (exact cov)") |>
                             rename("p_value_exact" = "p_value"),
                           x |>
                             filter(method == "nb_regression") |>
                             rename("p_value_nb" = "p_value") |>
                             select(p_value_nb, response_id, undercover_grna),
                           by = c("response_id", "undercover_grna")) |>
  mutate(pass_qc = (n_nonzero_treatment >= n_nonzero_treatment_thresh) & (n_nonzero_control >= n_nonzero_control_thresh))

comparison_df |>
  ggplot(mapping = aes(x = p_value_exact, y = p_value_nb, col = pass_qc)) +
  geom_point(alpha = 0.7, cex = 0.7) +
  geom_abline(slope = 1, intercept = 0, col = "darkred") +
  theme_bw() +
  scale_x_continuous(trans = revlog_trans(10)) +
  scale_y_continuous(trans = revlog_trans(10)) +
  xlab("p-value (SCEPTRE exact)") +
  ylab("p-value (NB regression)") +
  labs(col = "Retained after QC") +
  geom_vline(xintercept = 0.5, col = "darkred") +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(nrow=2, byrow=TRUE))
```

These results are even more striking than the results comparing SCEPTRE (exact) to SCEPTRE (SN). There exists a set of pairs for which the NB regression p-value is about 1 and the SCEPTRE (exact) p-value is in the interval (0, 1). (These are the points at the bottom of the plot.) We see that very few of these pairs pass QC. What is the deal with these pairs? I filter for pairs with NB p-values greater than 0.99 and SCEPTRE (exact) p-values less than 0.5. (This is the row of points at the bottom of the plot to the right of the vertical black line.)

```{r}
comparison_df |>
  filter(p_value_nb > 0.99,
         p_value_exact < 0.5) |>
  summarize(m = mean(n_nonzero_treatment == 0)) |>
  pull() * 100
```

Nearly all of these points (99.6%) have zero treatment cells with expression. We thus have an (at least proximate) explanation for the discrepancy between SCEPTRE (exact) and NB regression. When no treatment cell contains nonzero gene expression, SCEPTRE (exact) and NB regression both fail. SCEPTRE (exact) fails in a liberal direction, producing inflated p-values. NB regression, by contrast, fails in a conservative direction, yielding p-values equal to one. We likely will filter out such pairs as part of QC. Thus, on the pairs that we will subject to analysis, NB regression and SCEPTRE (exact) coincide fairly closely. (And in fact, SCEPTRE (exact) exhibits slightly better calibration on the QC'ed pairs, likely due to greater robustness to model misspecification.) The results are encouraging. After applying very mild QC, SCEPTRE emerges as the best method on both the Papalexi and Frangieh data. This is due to CAMP.

# Comparing the four versions of SCEPTRE

Here, I plot the four versions of SCEPTRE (with covariates vs. without covariates, skew-normal vs. exact) on the Papalexi and Frangieh data. I apply the mild QC used above. First, I examine the Frangieh IFN-gamma data.

```{r, echo = FALSE, fig.align = "center", fig.height = 6, fig.width = 6, message=FALSE, warning=FALSE}
p_qc <- res |>
  filter(dataset == "frangieh_ifn_gamma_gene",
         method %in% c("sceptre (exact no cov)",
                      "sceptre (exact cov)",
                      "sceptre (sn no cov)",
                      "sceptre (sn cov)"),
         n_nonzero_treatment >= n_nonzero_treatment_thresh,
         n_nonzero_control >= n_nonzero_control_thresh) |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("QC")

p_qc
```

Including or excluding covariates does not seem to have much of an effect (at least on type-I error control). The skew-normal approximation, by contrast, leads to inflation. Next, I examine the Papalexi gene expression data.

```{r, echo = FALSE, fig.align = "center", fig.height = 6, fig.width = 6, message=FALSE, warning=FALSE}
p_qc <- res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         method %in% c("sceptre (exact no cov)",
                      "sceptre (exact cov)",
                      "sceptre (sn no cov)",
                      "sceptre (sn cov)"),
         n_nonzero_treatment >= n_nonzero_treatment_thresh,
         n_nonzero_control >= n_nonzero_control_thresh) |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("QC")

p_qc
```

The results are fascinating: SCEPTRE (skew-normal and without covariates) performs the worst; SCEPTRE (exact and without covariates) performs second worst; next, SCEPTRE (skew-normal and with covariates) performs second best; finally, SCEPTRE (exact and with covariates) performs best. This result provides clear evidence that the skew-normal fit and confounding both pose challenges to calibration, with confounding being the more serious problem. I plot the results above on an untransformed scale.

```{r, echo = FALSE, fig.align = "center", fig.height = 6, fig.width = 6, message=FALSE, warning=FALSE}
p_qc <- res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         method %in% c("sceptre (exact no cov)",
                      "sceptre (exact cov)",
                      "sceptre (sn no cov)",
                      "sceptre (sn cov)"),
         n_nonzero_treatment >= n_nonzero_treatment_thresh,
         n_nonzero_control >= n_nonzero_control_thresh) |>
  ggplot(aes(y = p_value, 
         col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_reverse() +
   scale_y_reverse() +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(legend.position = "bottom",
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank()) +
  guides(color=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("QC")

p_qc
```

In the bulk the skew-normal fit causes more problems than confounding does.
