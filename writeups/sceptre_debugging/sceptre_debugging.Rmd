---
title: "Statistical debugging of `sceptre`"
author: "Tim"
date: "2022-09-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
devtools::load_all("~/research_code/sceptre2/")
devtools::load_all("~/research_code/lowmoi/")
library(tidyverse)
reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    scales::trans_new(paste0("reverselog-", format(base)), trans, inv, 
              scales::log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

# load results
sceptre_debug <- readRDS("/Users/timbarry/research_offsite/projects/sceptre2/results/undercover_grna_analysis/sceptre_debug.rds")

# define the categories
ks_stat_categories <- list(good = c(0, 1e-2),
                           adequate = c(1e-2, 5e-2),
                           subpar = c(5e-2, 0.1),
                           poor = c(0.1, 1))

# make some modifications to results
sceptre_debug <- sceptre_debug |>
  mutate(p_gap = abs(p_value - p_value_emp),
         p_rat = p_value_emp/p_value,
         ks_fit = cut(x = ks_stat,
                      breaks = unique(unlist(ks_stat_categories)),
                      labels = names(ks_stat_categories))) |>
  filter(dataset != "papalexi/eccite_screen/protein")
```

-   KS statistic as a good measure of fit quality.

-   The effect of poor fit quality on the p-value approximation.

-   The determinants of poor KS fit quality. Difference between low and high MOI.

-   Is poor skew-normal fit the primary (or at least a primary) cause of miscalibration? Examining qq-plots of p-values for the conditioned on different skew-normal fit quality.

-   Other issues - (1) the precomputation; is the precomputation "meaningful" for very small sample sizes? What might we do instead? (2) convergence of the skew-normal; are there issues? (3) is it possible that we are fitting too many covariates?

-   Conclusions and recommendations.

## The KS statistic is a good single-number summary for skew-normal quality of fit

First, I verified that the KS statistic is a good single-number summary of skew-normal fit quality. Based on visual inspection of many resampling distributions, I partitioned the KS statistics into four categories to simplify the analysis: good, adequate, subpar, and poor (see table below).

| KS statistic range          | Categorization |
|-----------------------------|----------------|
| 0 $\leq$ KS stat \< 0.01    | Good           |
| 0.01 $\leq$ KS stat \< 0.05 | Adequate       |
| 0.05 $\leq$ KS stat \< 0.1  | Subpar         |
| 0.1 $\leq$ KS stat          | Poor           |

```{r, include=FALSE,cache=TRUE}
set.seed(4)
n_categories <- length(ks_stat_categories)
cowplot_lists <- vector(mode = "list", length = n_categories)
names(cowplot_lists) <- names(ks_stat_categories)

for (category in names(ks_stat_categories)) {
  curr_range <- ks_stat_categories[[category]]
  sceptre_debug_sub <- sceptre_debug |>
    filter(dataset == "frangieh/co_culture/gene") |>
    filter(ks_stat >= curr_range[1], ks_stat < curr_range[2]) |>
    sample_n(4)
  ps <- lapply(X = seq(1, 4), FUN = function(i) {
    response_id <- sceptre_debug_sub[i, "response_id"] |> as.character()
    undercover_grna <- sceptre_debug_sub[i, "undercover_grna"] |> as.character()
    ks_stat <- sceptre_debug_sub[i, "ks_stat"]
    sceptre_args <- get_sceptre_function_args_for_pair(
      response_id = response_id, undercover_grna = undercover_grna,
      dataset_name = "frangieh/co_culture/gene", output_amount = 3, B = 2500)
    out <- do.call(what = sceptre2::run_sceptre_low_moi, args = sceptre_args)
    tit <- paste0("KS = ", round(ks_stat, 5))
    sceptre2::plot_fitted_density_result_row(out, legend = FALSE) + ggtitle(tit)
  })
  cowplot_lists[[category]] <- cowplot::plot_grid(plotlist = ps)
}
```

Let us look at four randomly-selected resampling distributions from each of these categories on the Frangieh co-culture gene expression data. Here are four undercover gRNA-gene pairs in the **good** category.

```{r, echo=FALSE}
plot(cowplot_lists$good)
```

Next, here are four in the **adequate** category.

```{r, echo=FALSE}
plot(cowplot_lists$adequate)
```

Next, here are four in the **subpar** category.

```{r, echo=FALSE}
plot(cowplot_lists$subpar)
```

Finally, here are four in the **poor** category.

```{r, echo=FALSE}
plot(cowplot_lists$poor)
```

The KS statistic appears to closely track fit quality. Also, as the fit gets worse, the skew-normal fit deviates more from the N(0,1) distribution.

I computed the fraction of pairs falling into each category for each dataset. I created a mosaic plot to visualize these data. We see that "good" is the most common category, although there is a fair amount of variation across datasets.

```{r, echo=FALSE}
skew_normal_fit <- sceptre_debug |>
  group_by(dataset) |>
  group_modify(.f = function(tab, key) {
    tab <- prop.table(table(tab$ks_fit))
    data.frame(good = tab[1], adequate = tab[2], subpar = tab[3], poor = tab[4])
  })
skew_normal_fit_m <- as.matrix(skew_normal_fit[,2:5])
#colnames(skew_normal_fit_m) <- paste0(colnames(skew_normal_fit_m))
#rownames(skew_normal_fit_m) <- skew_normal_fit$dataset
colnames(skew_normal_fit_m) <- rep("", ncol(skew_normal_fit_m))
rownames(skew_normal_fit_m) <- rep("", nrow(skew_normal_fit_m))
skew_normal_fit |> dplyr::mutate_at(.vars = c("good", "adequate", "subpar", "poor"), ~ round(., 3)) |> knitr::kable()
```

Color legend:

-   black = "good"

-   dark grey = "adequate"

-   light grey = "subpar"

-   white = "poor."

Datasets from left to right:

-   frangieh/co_culture/gene

-   frangieh/control/gene

-   schraivogel/ground_truth_tapseq/gene

-   schraivogel/enhancer_screen_chr11/gene

-   frangieh/ifn_gamma/gene

-   schraivogel/enhancer_screen_chr8/gene

-   papalexi/eccite_screen/gene

-   schraivogel/ground_truth_perturbseq/gene

-   simulated/experiment_1/gene.

```{r, echo=FALSE}
mosaicplot(skew_normal_fit_m, color = TRUE, main = "Mosaic plot of KS statistic fits")
```

## Relationship between goodness of fit and accuracy of the p-value approximation

I next investigated the relationship between goodness of the skew-normal fit (as quantified by the KS statistic) and accuracy of the skew-normal p-value. I calculated the discrepancy between the "true" empirical p-value $p_{emp}$ (carried out to $B = 100,000$ replicates) and the skew-normal p-value $p_{sn}$. I considered two measures of discrepancy: $p_{dif}$, the absolute value of the difference between the p-values (defined as $p_{dif} = |p_{emp} - p_{sn}|$), and $p_{rat}$, the ratio of the skew-normal p-value to the empirical p-value (defined as $p_{rat} = p_{sn}/p_{emp}$). The former measure is more meaningful for p-values in the bulk of the distribution, while the latter is more meaningful for p-values in the tail.

I plotted $p_{dif}$ and $p_{rat}$ against the KS statistic, coloring the pairs by fit quality ("good", "adequate", "subpar", and "poor") and faceting by dataset. First, examining $p_{dif}$, we see that as the skew-normal fit becomes worse, $p_{dif}$ increases in magnitude and become more variable.

```{r, echo = FALSE}
sceptre_debug_sub <- sceptre_debug |> 
  filter(p_value_emp > 100/100000)

ggplot(data = sceptre_debug_sub,
       mapping = aes(x = ks_stat, y = p_gap, col = ks_fit)) + 
  facet_wrap(. ~ dataset) +
  geom_point(cex = 0.3, alpha = 0.3) +
  scale_x_log10() +
  theme_bw() +
  guides(colour = guide_legend(override.aes = list(alpha = 1, cex = 1))) +
  ylab("p-dif") +
  xlab("Skew-normal fit quality") +
  labs(col = "SN Fit")
```

The corresponding plot for $p_{rat}$ is below. (The y-axis has been log-transformed. Also, $p_{rat}$ values of above 1,000 and below 0.001 have been excluded from the plot, causing many points in the "poor" category to not appear.)

Encouragingly, virtually every skew-normal p-value in the "good" category is well within an order of magnitude of the true empirical p-value. The same cannot be said about skew-normal p-values in the "poor" category.

```{r, echo = FALSE}
ggplot(data = sceptre_debug_sub |> filter(
  p_rat < 1e3, p_rat > 1e-3),
       mapping = aes(x = ks_stat, y = p_rat, col = ks_fit)) + 
  facet_wrap(. ~ dataset) +
  geom_point(cex = 0.5, alpha = 0.6) +
  scale_y_log10() +
  scale_x_log10() +
  theme_bw() +
  ylab("p-rat") +
  guides(colour = guide_legend(override.aes = list(alpha = 1, cex = 1))) +
  xlab("Skew-normal fit quality") +
  geom_hline(yintercept = 1) + 
  labs(col = "SN Fit")
```

Finally, I plotted the empirical p-values against the skew-normal p-values, separating the "good" and "poor" pairs into different figures and faceting by dataset. I performed a negative log 10 transformation of the axes to focus on the tail of the distributions. The plot below shows the "good" pairs. We see fairly good agreement between the empirical and skew-normal p-values, with mild discordance for the Frangieh datasets.

```{r, echo = FALSE}
ggplot(data = sceptre_debug_sub |> filter(p_value > 1e-8, ks_fit == "good"),
       mapping = aes(p_value, p_value_emp)) +
  geom_point(cex = 0.5, alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, col = "darkblue", lwd = 0.8) +
  facet_wrap(.~dataset) +
  theme_bw() +
  xlab("Skew-normal p") + ylab("Emprical p") +
  scale_x_continuous(trans=reverselog_trans(10)) +
  scale_y_continuous(trans=reverselog_trans(10))
```

The next plot shows the "poor" pairs. The disagreement between the empirical and skew-normal p-values is much more extreme.

```{r, echo = FALSE}
ggplot(data = sceptre_debug_sub |> filter(p_value > 1e-8, ks_fit == "poor"),
       mapping = aes(p_value, p_value_emp)) +
  geom_point(cex = 0.5, alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, col = "darkblue", lwd = 0.8) +
  facet_wrap(.~dataset) +
  theme_bw() +
  xlab("Skew-normal p") + ylab("Emprical p") +
  scale_x_continuous(trans=reverselog_trans(10)) +
  scale_y_continuous(trans=reverselog_trans(10))
```

Pairs above the blue line have a skew-normal p-value that is **larger** (i.e., less significant) than the empirical p-value. Pairs below the blue line, by contrast, have a skew-normal p-value that is **smaller** (i.e., more significant) than the empirical p-value. Pairs below the blue line therefore are more concerning than pairs above, and it is clear that pairs with a "poor" skew-normal fit are much more likely to fall far below the blue line than pairs with a "good fit." We can conclude that poor skew-normal fits are more likely to result in grossly inflated p-values than a good skew-normal fits.

Overall, these analyses indicate (perhaps unsurprisingly) that the quality of the skew-normal fit matters very much: good skew-normal fits lead to reasonably good p-value approximations; conversely, poor skew-normal fits lead to poor approximations.

## Determinants of poor skew-normal fit

I next sought to determine the determinants of skew-normal fit quality.

```{r, echo = FALSE}
ggplot(data = sceptre_debug,
       mapping = aes(x = n_treatment_cells_with_expression + 1,
                     y = ks_stat)) +
  geom_point(cex = 0.5, alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
   facet_wrap(.~dataset) +
  theme_bw()
```

```{r, echo = FALSE}
ggplot(data = sceptre_debug,
       mapping = aes(x = n_control_cells_with_expression + 1,
                     y = ks_stat)) +
  geom_point(cex = 0.5, alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
   facet_wrap(.~dataset) + theme_bw()
```

```{r, cache=TRUE, echo = FALSE}
library(mgcv)
# Fitting GAMs to each; two questions: (i) fraction deviance explained?
# (ii) what sample size do we need (for both treated and untreated) to have a "good" fit?
gam_out <- sceptre_debug |>
  select(dataset,
         ks_stat,
         n_treatment_cells_with_expression,
         n_control_cells_with_expression) |>
 mutate(lg_ks_stat = log(ks_stat),
           lg_n_treatment = log(n_treatment_cells_with_expression + 1),
           lg_n_control = log(n_control_cells_with_expression + 1)) |>
  group_by(dataset) |>
  group_map(.f = function(tbl, key) {
    fit_n_treatment <- gam(formula = lg_ks_stat ~ s(lg_n_treatment), data = tbl)
    fit_n_control <- gam(formula = lg_ks_stat ~ s(lg_n_control), data = tbl)
    fit_both <- gam(formula = lg_ks_stat ~ s(lg_n_treatment) + s(lg_n_control), data = tbl)
    
    dev_explained_n_treatment <- summary(fit_n_treatment)$dev.expl
    dev_explained_n_control <- summary(fit_n_control)$dev.expl
    dev_explained_both <- summary(fit_both)$dev.expl
    
    list(dataset = as.character(key$dataset),
         dev_explained_n_treatment = dev_explained_n_treatment,
         dev_explained_n_control = dev_explained_n_control,
         dev_explained_both = dev_explained_both)
  })
```

```{r}
dev_explained <- data.frame(
  dataset = sapply(gam_out, function(elem) elem[["dataset"]]),
  dev_explained_n_treatment = sapply(gam_out, function(elem) elem[["dev_explained_n_treatment"]]),
  dev_explained_n_control = sapply(gam_out, function(elem) elem[["dev_explained_n_control"]]),
  dev_explained_both = sapply(gam_out, function(elem) elem[["dev_explained_both"]])) |>
  mutate_at(c("dev_explained_n_treatment",
              "dev_explained_n_control",
              "dev_explained_both"), ~round(., 3))
dev_explained |> knitr::kable()
```
