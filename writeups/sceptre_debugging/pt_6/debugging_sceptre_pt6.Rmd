---
title: 'Debugging sceptre pt 6: running SCEPTRE without covariates'
author: "Tim"
date: "2022-10-29"
output: html_document
---

```{r, message=FALSE, error=FALSE, warning=FALSE, echo=FALSE}
library(katlabutils)
library(tidyverse)
result_dir <- paste0(.get_config_path("LOCAL_SCEPTRE2_DATA_DIR"), "results/")

# load results
# 1. sceptre (with covariates)
sceptre_res_cov <- readRDS(paste0(result_dir,
                                  "undercover_grna_analysis/undercover_result_grp_size_1_sceptre.rds")) |>
  select(-clock_time, -max_ram)

# 2. sceptre (without covariates)
sceptre_res_no_cov <- readRDS(paste0(result_dir,
                                     "undercover_grna_analysis/sceptre_debug_no_cov.rds"))
funct_script <- paste0(.get_config_path("LOCAL_CODE_DIR"), "sceptre2-manuscript/writeups/undercover_results_eda/analyze_undercover_results_plot_functs.R")

# 3. Fisher exact
fisher_exact_res <- readRDS(paste0(result_dir, "undercover_grna_analysis/fisher_exact_1.rds"))

# 4. Seurat DE
seurat_res <- readRDS(paste0(result_dir,
                             "undercover_grna_analysis/undercover_result_grp_size_1.rds")) |>
  dplyr::select(-clock_time, -max_ram) |>
  filter(method == "seurat_de")

# 5. positive control results (ungrouped)
pc_res_singleton <- readRDS(paste0(result_dir,
                                   "positive_control_analysis/pc_results_singleton.rds")) |>
  rename("grna_id" = "grna_group")

# 6. NB regression
nb_reg_res <- readRDS(paste0(result_dir, "undercover_grna_analysis/undercover_result_grp_size_1.rds")) |>
  dplyr::select(-clock_time, -max_ram) |>
  dplyr::filter(method %in% c("nb_regression"))

# 7. sceptre KDE results
sceptre_debug_ke <- readRDS(paste0(result_dir,
                                   "undercover_grna_analysis/sceptre_debug_kde.rds"))
source(funct_script)

# 8. sample size df
sample_size_df <- readRDS(paste0(result_dir, "dataset_sample_sizes/n_nonzero_cells_per_grna.rds")) |>
  dplyr::mutate(dataset = dataset_concat,
                dataset_concat = NULL, paper = NULL, modality = NULL) |>
  dplyr::rename(grna_group = target, response_id = feature_id) |>
  filter(grna_group == "non-targeting")
```

```{r, message=FALSE, error=FALSE, warning=FALSE, echo=FALSE}
replace_slash_w_underscore <- function(df) {
  df |> dplyr::mutate(dataset = gsub(pattern = "/",
                                replacement = "_",
                                fixed = TRUE,
                                x = dataset))
}

sceptre_res_cov <- sceptre_res_cov |>
  mutate(method = factor("sceptre (covariates)"))

sceptre_res_no_cov <- sceptre_res_no_cov |>
  mutate(method = factor("sceptre (no covariates)"))

undercover_res <- rbind(sceptre_res_cov,
                        sceptre_res_no_cov,
                        seurat_res,
                        fisher_exact_res,
                        nb_reg_res) |>
  replace_slash_w_underscore()

pc_res_singleton <- pc_res_singleton |>
  replace_slash_w_underscore() |>
  update_dataset_names()

undercover_res_kde <- rbind(
  sceptre_res_cov |> mutate(method = factor("sceptre (sn)")),
  sceptre_debug_ke |> mutate(method = factor("sceptre (kde)")),
  seurat_res,
  fisher_exact_res
) |> replace_slash_w_underscore() |>
  update_dataset_names() |>
  combine_schraivogel_enhancer_screens()

sample_size_df <- sample_size_df |>
  replace_slash_w_underscore() |>
  combine_schraivogel_enhancer_screens()

ks_stat_categories <- list(good = c(0, 1e-2),
                           adequate = c(1e-2, 5e-2),
                           subpar = c(5e-2, 0.1),
                           poor = c(0.1, 1))
```

```{r, message=FALSE, error=FALSE, warning=FALSE, echo=FALSE}
ntc_effective_samp_size <- sample_size_df |>
  filter(grna_group == "non-targeting") |>
  group_by(response_id, dataset) |>
  summarize(effective_samp_size = sum(n_nonzero_cells))

sample_size_df <- left_join(x = sample_size_df,
                            y = ntc_effective_samp_size,
                            by = c("response_id", "dataset")) |>
  mutate(n_nonzero_treatment = n_nonzero_cells,
         n_nonzero_control = effective_samp_size - n_nonzero_cells) |>
  select(response_id,
         undercover_grna = grna_id,
         n_nonzero_treatment,
         n_nonzero_control,
         dataset)

undercover_res <- left_join(undercover_res, sample_size_df, c("response_id", "undercover_grna", "dataset"))
undercover_res_kde <- left_join(undercover_res_kde, sample_size_df, c("response_id", "undercover_grna", "dataset"))
```

In this writeup I am to answer the following questions.

1. What happens when we apply SCEPTRE without covariates (aside from library size) to the data? Does calibration improve or get worse? What does this tell us about confounding, nuissance, etc.?

2. Does using kernel density estimation (instead of a skew-normal) to model the null distribution improve the accuracy of the p-value estimate?

First, I deploy SCEPTRE without covariates on the Papalexi data. Next, I turn to the Frangieh data. (I omit the Schraivogel data from this analysis.)

# SCEPTRE without covariates: Papalexi data

I applied SCEPTRE to the Papalexi data, including only log-transformed library size as a covariate. (In other words, the remaining covariates, including batch, biological replicate, percent mitochondrial reads, etc., were excluded). Below, I plot the results on the Papalexi data. I include five methods: (i) SCEPTRE with covariates, (ii) SCEPTRE without covariates, (iii) Fisher exact test, (iv) Seurat DE, and (v) NB regression. I exclude NT8 from this plot, as NT8 is an outlier NTC (Gene's writeup): it is expressed in many fewer cells than the other NT gRNAs.

We see that NB regression and Fisher's exact test appear to exhibit the best calibration, followed by SCEPTRE (with covariates). SCEPTRE (without covariates) and Seurat DE lag behind. This is an interesting (and in my opinion exciting) result for two reasons. First, it suggests that the main limitation of Seurat DE on the Papalexi data is lack of confounder adjustment. Second, it is the first empirical evidence that I have seen of "implicit confounder adjustment," the phenomenon by which including confounders in a GLM-based permutation test improves the type-I error of the test (assuming that the underlying GLM reasonably well-specified). Note that I have included biological replicate but not lane as a covariate. Gene's propensity score analysis indicates that lane likely confounds gRNA presence/absence as well. Therefore, in subsequent analyses, we should include lane as a covariate alongside biological replicate. It is worth noting that both versions of SCEPTRE exhibit worse calibration in the bulk of the distribution (i.e., expected quantile < 0.01) than the other methods. I suspect that this is due to the skew-normal fit. We should see if we can remedy this by using a skew-t fit or an exact permutation test. It might also be the case that we are "overfitting" and should use one batch of test statistics to fit the skew-normal distribution and another to estimate the p-value.

```{r, message = FALSE, echo = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}
undercover_res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         undercover_grna != "NTg8") |>
  ggplot(mapping = aes(y = p_value, col = method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

Below, I plot these same results on an untransformed scale.

```{r, message = FALSE, echo = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}
undercover_res |>
  filter(dataset == "papalexi_eccite_screen_gene",
         undercover_grna != "NTg8") |>
  ggplot(mapping = aes(y = p_value, col = method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_reverse() +
   scale_y_reverse() +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

Why is Fisher's exact test calibrated despite the fact that it does not adjust for confounders? Fisher's exact test is underpowered on the Papalexi data, making its calibration challenging to assess. Below, I plot the number of discoveries that each method makes on the (ungrouped) positive control Papalexi data. (Note: SCEPTRE here refers to SCEPTRE with covariates.) Fisher's exact test makes only about 70\% the number of discoveries that SCEPTRE and Seurat DE make. Thus, Fisher's exact test is underpowered to pick up on the "signal" injected into the negative control data by the confounders.

```{r, message = FALSE, echo = FALSE, warning = FALSE, fig.height = 5, fig.width = 5, fig.align = "center"}
pc_res_singleton |>
  filter(dataset == "papalexi_eccite_screen_gene",
         !(method %in% c("liscovitch_method", "weissman_method"))) |>
  compute_n_bonf_rejected() |>
  make_n_rejected_pairs_plot(y_max = NULL,
                             scales = "free",
                             log_trans = FALSE)
```

I next plot the results on the Papalexi protein data. The results are similar to the gene expression results. SCEPTRE (with covariates) and NB regression exhibit very good calibration. The other methods (including SCEPTRE without covariates and Fisher exact test), by contrast, exhibit inflation. This likely is because there is confounding, and SCEPTRE and NB regression are the only methods that adjust for confounding. The Fisher exact test likely exhibits inflation on the protein data but not on the gene expression data because the protein data are much more highly expressed than the gene expression data and thus contain more "signal." I do not believe that Gene included the Papalexi protein data in his propensity score analysis. It would be good to do a propensity score analysis of the protein data to confirm that confounding is present.

```{r, message = FALSE, echo = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}
undercover_res |>
  filter(dataset == "papalexi_eccite_screen_protein") |>
  ggplot(mapping = aes(y = p_value, col = method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

We also should assess the power of the methods on the Papalexi protein data. I have updated the codebase to this end and will execute the relevant code in a subsequent iteration of generating the results.

# SCEPTRE without covariates: Frangieh data

I also applied SCEPTRE without covariates (except for log-transformed library size) on the Frangieh data. The results are below. Fisher exact test exhibits the best calibration. SCEPTRE (with and without covariates) and Seurat DE are equally bad. Finally, NB regression (suprisingly) is intermediate.

```{r, message = FALSE, echo = FALSE, warning=FALSE, fig.height = 12, fig.width = 8, fig.align = "center"}
undercover_res |>
  filter(dataset %in% c("frangieh_co_culture_gene",
                         "frangieh_control_gene",
                         "frangieh_ifn_gamma_gene")) |>
    update_dataset_names() |>
  ggplot(mapping = aes(y = p_value, col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
  facet_grid(dataset ~ .) +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

I plot the same results, this time filtering for pairs with number of treatment cells with nonzero expression > 30.

```{r, message = FALSE, echo = FALSE, fig.height = 12, fig.width = 8, fig.align = "center"}
undercover_res |>
  filter(dataset %in% c("frangieh_co_culture_gene",
                         "frangieh_control_gene",
                         "frangieh_ifn_gamma_gene"),
         n_nonzero_treatment >= 30) |>
    update_dataset_names() |>
  ggplot(mapping = aes(y = p_value, col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
  facet_grid(dataset ~ .) +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

The calibration generally improves across methods (including those that do not adjust for confounders, such as Seurat DE). This is consistent with the hypothesis that the Frangieh data are (mostly) unconfounded. If the Frangieh data *were* confounded, then (i) there would be a bigger difference between SCEPTRE (with covarites) and SCEPTRE (without covariates), and (ii) the methods that *do not* adjust for confounding (namely, SCEPTRE without covariates and Seurat DE) would not improve so drastically as we apply more stringent QC.

# Nonparametric density fitting

The skew-normal fit clearly is unsatisfactory for many of the pairs that we are testing across datasets (writeup 1). I instead use a Gaussian KDE to fit the null distribution of resampled test statistics. I applied SCEPTRE (with covariates) to the data, using both KDE and a skew-normal to fit the null distribution of test statistics. First, I plot the results on the Frangieh data. We see that SCEPTRE (with KDE) performs slightly better than the other methods (aside from Fisher exact).

```{r, message = FALSE, echo = FALSE, fig.height = 12, fig.width = 8, fig.align = "center", warning = FALSE}
undercover_res_kde |>
  filter(dataset %in% c("frangieh_co_culture_gene",
                         "frangieh_control_gene",
                         "frangieh_ifn_gamma_gene")) |>
  ggplot(mapping = aes(y = p_value, col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
  facet_grid(dataset ~ .) +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

I plot the same results, this time filtering for pairs with at least 30 treatment cells with nonzero expression. Strangely, SCEPTRE (KDE) does not change much!

```{r, message = FALSE, echo = FALSE, fig.height = 12, fig.width = 8, fig.align = "center", warning = FALSE}
undercover_res_kde |>
  filter(dataset %in% c("frangieh_co_culture_gene",
                         "frangieh_control_gene",
                         "frangieh_ifn_gamma_gene"),
         n_nonzero_treatment >= 30) |>
  ggplot(mapping = aes(y = p_value, col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
  facet_grid(dataset ~ .) +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

Next, I plot the results on the Papalexi gene data. Surprisingly, SCEPTRE (KDE) performs the worst.

```{r, message = FALSE, echo = FALSE, warning = FALSE, fig.height = 6, fig.width = 8, fig.align = "center"}
undercover_res_kde |>
  filter(dataset == "papalexi_eccite_screen_gene",
         undercover_grna != "NTg8") |>
    update_dataset_names() |>
  ggplot(mapping = aes(y = p_value, col = Method)) +
   stat_qq_points(ymin = 1e-9, size = 0.8) +
   geom_abline(col = "darkred") +
  facet_grid(dataset ~ .) +
   stat_qq_band() +
   theme_bw() +
   scale_x_continuous(trans = revlog_trans(10)) +
   scale_y_continuous(trans = revlog_trans(10)) +
   labs(x = "Expected quantile", y = "Observed quantile") +
   theme(panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         panel.background = element_blank())
```

Overall, using KDE does not appear to be a promising strategy. Why is this the case? I plot one of the pairs on the Papalexi data for which KDE yields an inflated p-value. The original test statistic is denoted with the vertical black line. I use 10,000 samples to compute the KDE p-value and 200,000 to compute the (exact) empirical p-value. Their values are shown below.

```{r, message = FALSE, echo = FALSE, warning=FALSE, fig.height = 6, fig.height = 6, fig.align = "center"}
problem_pairs <- undercover_res_kde |>
  filter(dataset == "papalexi_eccite_screen_gene",
         method == "sceptre (kde)",
         p_value < 1e-7)

ex_pair <- problem_pairs |>
  slice(8)
response_id <- ex_pair$response_id |> as.character()
undercover_grna <- ex_pair$undercover_grna |> as.character()

sceptre_args <- lowmoi::get_sceptre_function_args_for_pair(
  response_id = response_id,
  undercover_grna = undercover_grna,
  dataset_name = "papalexi/eccite_screen/gene",
  output_amount = 3,
  B = 200000)

out <- do.call(what = sceptre2::run_sceptre_low_moi, args = sceptre_args)
z_null <- out |> select(starts_with("z_null")) |> as.numeric()
z_star <- out$z_value
out <- out |> select(-starts_with("z_"))
hist(z_null, breaks = 50)
abline(v = z_star)
emp_p <- out$p_value_emp
z_null_samp <- sample(z_null, replace = FALSE, size = 10000)

compute_kde_p_value <- function(z_null_samp, z_star) {
  bw <- stats::bw.SJ(z_null_samp)
  l_p <- mean(pnorm(z_star, z_null_samp, bw))
  r_p <- 1 - l_p
  p <- 2 * min(l_p, r_p)
  return(p)
}

kde_p <- compute_kde_p_value(z_null_samp, z_star)
```

```{r}
emp_p
kde_p
```

The sample size information for this pair is printed below.

```{r}
out[,c("n_treatment_cells_with_expression",
       "n_treatment_cells_without_expression",
       "n_control_cells_with_expression",
       "n_control_cells_without_expression")]
```

We see that the sample sizes are fairly small. It is quite challenging to accurately estimate the long and heavy tail of this distribution. The tail estimated by KDE likely decays too quickly. I have reached the conclusion that adequately estimating the density of the resampling distribution in challenging problem settings likely is impossible. Other strategies (e.g., doing many resamples or conducting a Fisher exact test) probably will have to be used instead.
